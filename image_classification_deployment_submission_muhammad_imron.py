# -*- coding: utf-8 -*-
"""Image Classification Deployment Submission Muhammad Imron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TDt7zpr2b4swsAvdpD8KxU_G6hPPf6h8

Hallo, Kak Reviewer. 

Perkenalkan, namaku Muhammad Imron, bisa dipanggil Imron. Di submission akhir ini, aku pakai dataset dari Kaggle yang namanya Dataset Zanthoxyli Pericarpium. Dataset itu berupa dataset gambar tanaman herbal dari China yang jumlahnya sekitar 70k,terdiri dari lima kelas. Rencananya di submission ini aku bakalan nerapin image classification buat jenis-jenis tanaman herbal Zanthoxyli Pericarpium. Selain itu, aku juga bakalan nerapin saving model menggunakan TF Lite.

Mohon bantuannya kak, untuk direview.

Terima kasih

---

https://www.kaggle.com/datasets/chaoquntan/image-dataset-of-zanthoxyli-pericarpium

# Download Dataset dari Kaggle
"""

!pip install kaggle

!mkdir ~/.kaggle

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download chaoquntan/image-dataset-of-zanthoxyli-pericarpium --unzip

"""# Persiapan Library"""

!pip install split-folders

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import random
import cv2
import os
import PIL
import pathlib
import splitfolders

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications import DenseNet201
from tensorflow.keras.layers import (
    Dense,
    Dropout,
    Conv2D,
    MaxPool2D,
    Flatten,
    Input
)
from tensorflow.keras.models import Sequential
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator

"""# Data Exploration

Disini aku bakalan cek ada ukuran dataset, size setiap kelas, dan size gambarnya beragam atau ngga
"""

hong_sichuan = [img for img in os.listdir(f'{base_ds}/0hong_sichuan') if img.endswith('.jpg')]
qing_qingjiao = [img for img in os.listdir(f'{base_ds}/1qing_qingjiao') if img.endswith('.jpg')]
qing_tengjiao = [img for img in os.listdir(f'{base_ds}/2qing_tengjiao') if img.endswith('.jpg')]
hong_derong = [img for img in os.listdir(f'{base_ds}/3hong_derong') if img.endswith('.jpg')]
hong_hanyuan = [img for img in os.listdir(f'{base_ds}/4hong_hanyuan') if img.endswith('.jpg')]

herbal = [hong_sichuan, qing_qingjiao, qing_tengjiao, hong_derong, hong_hanyuan]
herbal_classes = []

for i in os.listdir('/content/images/train'):
  herbal_classes+=[i]
herbal_classes.sort()

image_count = len(list(base_ds.glob('*/*.jpg')))
print(f'Total image: {image_count}')
print(f'Total number of classes: {len(herbal_classes)}')
count = 0
herbal_count = []
for i in herbal_classes:
  print(f'Total {i} images: {len(herbal[count])}')
  herbal_count.append(len(herbal[count]))
  count += 1

sns.set_style('darkgrid')
sns.barplot(x = herbal_classes, y = herbal_count, palette = 'Blues_d')
plt.show()

sample_img = cv2.imread('/content/pictures/0hong_sichuan/1000.jpg')
plt.imshow(sample_img)
print(f'Image dimensions: {sample_img.shape}')

sample_img_2 = cv2.imread('/content/pictures/1qing_qingjiao/10003.jpg')
plt.imshow(sample_img_2)
print(f'Image dimensions: {sample_img_2.shape}')

def load_random_img(dir, label):
  plt.figure(figsize = (10,10))
  i = 0
  for label in herbal_classes:
    i += 1
    plt.subplot(1, 5, i)
    file = random.choice(os.listdir(f'{dir}/{label}'))
    image_path = os.path.join(f'{dir}/{label}', file)
    image = cv2.imread(image_path)
    plt.title(label)
    plt.imshow(image)
    plt.grid(None)
    plt.axis('off')

for i in range(2):
  load_random_img(base_ds, herbal_classes)

"""# Splitting Train dan Test

Karena datasetnya berupa gambar, dari sepengetahuanku ada dua pilihan buat split folder gambar, bisa pakai library splitfolders atau validation_split di Image Generator. Di submission ini aku nerapin splitfolders dengan ratio sesuai kriteria submission, 0.8 untuk training, dan 0.2 untuk validation
"""

base_ds = pathlib.Path('/content/pictures')
splitfolders.ratio(base_ds, output='images', seed=123, ratio=(0.8,0.2),group_prefix=None)

"""# Data Augmentation"""

data_generator = ImageDataGenerator(rescale=1./255)

train = data_generator.flow_from_directory(
    '/content/images/train',
    target_size=(150, 150), # resize image
    batch_size=8,
    class_mode='categorical'
)
val = data_generator.flow_from_directory(
    '/content/images/val',
    target_size=(150, 150),
    batch_size=16,
    class_mode='categorical'
)

"""# Build, Compile, and Fitting Model"""

model = tf.keras.models.Sequential([
    DenseNet201(weights="imagenet", include_top=False, input_tensor=Input(shape=(150, 150, 3))),
    Conv2D(128, (3,3), activation='relu', padding = 'same'),
    Conv2D(128, (3,3), activation='relu', padding = 'same'),
    MaxPool2D((2,2), padding='same'),
    Flatten(), 
    Dense(512, activation='relu'),
    Dense(128, activation='relu'),
    Dense(5, activation='softmax')  
])
model.layers[0].trainable = False

model.compile(optimizer=tf.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

"""Callbacks"""

# reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)
early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)

callbacks=[early_stopping]

history = model.fit(train,
                    validation_data=val,
                    epochs=50,
                    callbacks=callbacks)

"""# Evaluasi Model"""

score = model.evaluate(val, verbose=1)

def plot_train_history(history):
  plt.figure(figsize=(15,5))
  plt.subplot(1,2,1)
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('Model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'validation'], loc='upper left')

  plt.subplot(1,2,2)
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('Model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train', 'validation'], loc='upper left')
  plt.show()

plot_train_history(history)

"""# Saving Model into TF Lite Format"""

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)
 
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
 
tflite_model_file = pathlib.Path('model.tflite')
tflite_model_file.write_bytes(tflite_model)